{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6a7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated \n",
    "from typing_extensions import TypedDict \n",
    "from langgraph.graph import StateGraph , START , END \n",
    "from langgraph.graph.message import add_messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f30db7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[list, add_messages] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4011d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4230dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "from langchain.chat_models import init_chat_model \n",
    "llm = ChatGroq(model = \"llama3-8b-8192\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8982cdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000140D5519C40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000140D5519F70>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=init_chat_model(\"groq:llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a63aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ee579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder=StateGraph(State)\n",
    "graph_builder.add_node(\"llmchatbot\",chatbot)\n",
    "graph_builder.add_edge(START,\"llmchatbot\")\n",
    "graph_builder.add_edge(\"llmchatbot\",END)\n",
    "graph=graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bbce3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9a0437b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83bcd659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is langgraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'What is LangGraph? - IBM',\n",
       "   'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "   'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agentâ€™s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',\n",
       "   'score': 0.94401723,\n",
       "   'raw_content': None},\n",
       "  {'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "   'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "   'content': 'LangGraph is a Python library that helps you build applications like chatbots or AI agents by organizing their logic step-by-step using state machine model. This step configures your Gemini API key and then we create a simple function ask_gemini that takes user input, sends it to the Gemini model and returns the AI-generated response. Creates a state structure with three fields: question, classification and response which flows through the LangGraph. import matplotlib.pyplot as plt from langgraph.graph import StateGraph\\u200bbuilder = StateGraph(GraphState)builder.add_node(\"classify\", classify)builder.add_node(\"respond\", respond)builder.set_entry_point(\"classify\")builder.add_edge(\"classify\", \"respond\")builder.set_finish_point(\"respond\")app = builder.compile()\\u200bdef visualize_workflow(builder): G = nx.DiGraph()\\u200b for node in builder.nodes: G.add_node(node) for edge in builder.edges: G.add_edge(edge[0], edge[1])\\u200b pos = nx.spring_layout(G) nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=12, font_weight=\"bold\", arrows=True)  plt.title(\"Langchain Workflow Visualization\") plt.show()\\u200bvisualize_workflow(builder)',\n",
       "   'score': 0.91137725,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.43}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tool=TavilySearch(max_results=2)\n",
    "tool.invoke(\"What is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
